# Project Name

**[CVE-Report]**

## Description

This Python project is designed to retrieve information about Common Vulnerabilities and Exposures (CVEs) from the National Vulnerability Database (NVD) and generate a PDF document containing detailed information about a specified CVE. It also has the capability to search for and download related exploits from the Exploit-DB website. The project comprises two Python scripts:

NVD Data Scraper (First Script):

Fetches information about a specific CVE from the NVD website.
Generates a PDF report containing details such as CVE ID, publication date, CVSS score, CVSS vector, description, related hyperlinks, affected software versions, and any available exploits.
Utilizes libraries like Requests, BeautifulSoup, and ReportLab.
Exploit-DB Search and Download (Second Script):

Uses Selenium with Chrome WebDriver to search for exploits related to a specified CVE on the Exploit-DB website.
Downloads any available exploits and stores them on the user's system.
Requires Chrome WebDriver and handles the download process using Chrome.
Imports the ExportPdf function from the first script to generate a PDF report.

## Dependencies

- Python (version 3.11.4)
- Selenium (version 4.12.0)
- BeautifulSoup4 (version 4.12.2)
- ReportLab (version 4.0.4)

## Instructions for Running the Project

1. Clone this repository to your local machine.
2. Install the required dependencies using pip:
*pip install -r requirements.txt*

3. Run the second script *main.py*, providing the desired CVE ID as input. 
    This script will:
        * Search for exploits related to the CVE on Exploit-DB.
        * Generate a PDF report using the ExportPdf function from the first script.
        * Download the PDF report using a web browser.

## Group Members and Roles

- **[Huseyn_Abdullayev]** - Project Lead Developer
- **[Elvin_IsmayÄ±lov]** - Developer
- **[Tural_Huseynov]** - Research and Testing
- **[Raqsana_Aliyeva]** - Documentation and Reporting



## Additional Information about the project

The Role of Selenium in Enhancing CVE Data Retrieval: Extracting Insights from Dynamic Websites

In the code we provided, Selenium is used to automate interactions with a website (specifically, "https://www.cvedetails.com/cve-details.php") in order to extract information about Common Vulnerabilities and Exposures (CVE) details. Here's why Selenium is being used in this context:

Dynamic Website: The website we are scraping appears to be dynamic, meaning that it relies on JavaScript to load and display content. Selenium is capable of rendering web pages with JavaScript, which is essential for scraping such websites. This allows we to access and extract information that may not be present in the initial HTML source code.

Automated Interaction: Selenium enables we to interact with the web page as if a human user were using a web browser. In our code, we are using Selenium to open the CVE details page and locate specific elements using XPath, such as the affected links.

Web Scraping Beyond API: While we are using the "cve.circl.lu" API to obtain some CVE information, the website "https://www.cvedetails.com" may provide additional data or details that are not available through the API. Selenium allows we to scrape data directly from the web page, complementing the information obtained from the API.

Element Location: We are using Selenium to locate and interact with specific elements on the web page. In this case, we are finding elements with the XPath expression '//*[@id="vulnprodstable"]/tbody/tr/td[9]/a[1]' to retrieve affected links. Selenium makes it easy to perform such element locating and interaction tasks.

Overall, Selenium is used here to combine data from both an API (cve.circl.lu) and a dynamic website ("https://www.cvedetails.com") to gather comprehensive information about a CVE ID. While the API provides structured data, Selenium helps we access additional data that may be available only through web scraping.


Dual Data Sources
 Leveraging cve.circl.lu API and Web Scraping from www.cvedetails.com for Comprehensive CVE Information Retrieval
cve.circl.lu: This website is used as an API endpoint to fetch information about a specific CVE (Common Vulnerabilities and Exposures) ID. It provides structured data about vulnerabilities, including details such as Common Attack Pattern Enumeration and Classification (CAPEC) information, CVSS (Common Vulnerability Scoring System) vector, and references. This API is a convenient and reliable source for CVE-related data, making it a valuable resource for gathering standardized information about vulnerabilities.

www.cvedetails.com: This website is used for web scraping. It is accessed to gather additional information about a CVE ID that may not be available through the cve.circl.lu API. While the API provides structured data, some websites may offer more detailed or supplementary information, and this website is used to extract such data. Selenium is employed to automate interactions with the website and extract specific details, such as affected links, from its dynamic web pages.

In summary, these two websites are used in combination to gather comprehensive information about a specific CVE ID. The cve.circl.lu API is used for standardized vulnerability data, while www.cvedetails.com is accessed for any additional insights that might be available only through web scraping. This approach ensures that as much relevant information as possible is collected for the given CVE ID.



Certainly, let's break down the provided Python code step by step:

Importing Libraries:

from selenium import webdriver: This line imports the webdriver module from the Selenium library, which is used for browser automation.
from selenium.webdriver.common.by import By: It imports the By class from Selenium, which is used to specify how to locate web elements on a web page.
import json and import requests: These imports are for handling JSON data and making HTTP requests, respectively.
CVE ID Definition:

cve_id = "CVE-2010-3333": This line assigns the CVE ID "CVE-2010-3333" to the variable cve_id. This ID will be used for fetching CVE-related information.
cve_api Function:

This function is defined to retrieve information about a CVE from the "cve.circl.lu" API.
It takes a CVE ID as a parameter.
Constructs the API URL based on the provided CVE ID.
Makes an HTTP GET request to the API and checks if the response status code is 200 (OK).
If the response is successful, it parses the JSON response into a Python dictionary.
It extracts specific information from the JSON, such as CAPEC data, CVSS vector, and references, and stores it in a result dictionary.
Finally, it returns the result dictionary or False if the request was unsuccessful.
get_cve_details Function:

This function is defined to scrape additional information about a CVE from the "www.cvedetails.com" website.
It takes a CVE ID as a parameter.
Constructs the URL of the CVE details page on "www.cvedetails.com" using the provided CVE ID.
Initializes a web browser (Microsoft Edge in this case) using Selenium's webdriver and opens the specified URL.
Uses Selenium to locate affected links on the web page by specifying an XPath expression.
Prints the elements found (in this case, affected links) on the web page.
Main Execution Block:

if __name__ == '__main__': ensures that the following code block only runs if the script is executed directly (not imported as a module).
get_cve_details(cve_id) calls the get_cve_details function with the CVE ID "CVE-2010-3333" as an argument, initiating the web scraping process for this particular CVE.
In summary, this code defines two functions, one for fetching structured CVE data from the "cve.circl.lu" API and the other for scraping additional details from the "www.cvedetails.com" website using Selenium. The main block of code calls the scraping function for the specified CVE ID.



